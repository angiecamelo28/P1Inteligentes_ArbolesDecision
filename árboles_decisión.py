# -*- coding: utf-8 -*-
"""Copia de Árboles_Decisión.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fdCXgMKnvdkfzXwgfThNBz3bzksm3698
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import colors

import seaborn as sb

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn import metrics

from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_graphviz
import graphviz

from google.colab import files
import io
archivo=files.upload()

dtype_dict = { 'Gender':str,'Age':int,'Height':float,'Weight':float,
    'family_history_with_overweight':str,'FAV':str,'FCVC':int,'NCP':int,
    'CAEC':str,'SMOKE':str,'CH2O':int,'SCC':str,'FAF':int,'TUE':int,
    'CALC':str,'MTRANS':str,'NObeyesdad':str
}

dataframe=pd.read_csv(io.BytesIO(archivo['ObesidadDataSet.csv']),delimiter=";",dtype=dtype_dict)

"""**Eliminación de datos atípicos**"""

lim_inf_age = 14
lim_sup_age = 61

lim_inf_weight = 39
lim_sup_weight = 143

lim_inf_height = 1.45
lim_sup_height = 1.98

df_cleaned = dataframe[
    (dataframe['Age'] >= lim_inf_age) & (dataframe['Age'] <= lim_sup_age) &
    (dataframe['Weight'] >= lim_inf_weight) & (dataframe['Weight'] <= lim_sup_weight) &
    (dataframe['Height'] >= lim_inf_height) & (dataframe['Height'] <= lim_sup_height)
]

print(f'Tamaño del dataset original: {dataframe.shape}')
print(f'Tamaño del dataset "limpiado": {df_cleaned.shape}')

import plotly.express as px

fig_age_original = px.histogram(dataframe, x='Age', title='Distribución de Age (Original)')
fig_age_cleaned = px.histogram(df_cleaned, x='Age', title='Distribución de Age (Limpiada)')

fig_weight_original = px.histogram(dataframe, x='Weight', title='Distribución de Weight (Original)')
fig_weight_cleaned = px.histogram(df_cleaned, x='Weight', title='Distribución de Weight (Limpiada)')

fig_height_original = px.histogram(dataframe, x='Height', title='Distribución de Height (Original)')
fig_height_cleaned = px.histogram(df_cleaned, x='Height', title='Distribución de Height (Limpiada)')

fig_age_original.show()
fig_age_cleaned.show()
fig_weight_original.show()
fig_weight_cleaned.show()
fig_height_original.show()
fig_height_cleaned.show()

"""**Transformación de categorías de texto a número**"""

encoderGender=LabelEncoder()
dataframe["Gender"]=encoderGender.fit_transform(dataframe["Gender"])

encoderFamiliHistory=LabelEncoder()
dataframe["family_history_with_overweight"]=encoderFamiliHistory.fit_transform(dataframe["family_history_with_overweight"])

encoderFAVC=LabelEncoder()
dataframe["FAVC"]=encoderFAVC.fit_transform(dataframe["FAVC"])

encoderCAEC=LabelEncoder()
dataframe["CAEC"]=encoderCAEC.fit_transform(dataframe["CAEC"])

encoderSMOKE=LabelEncoder()
dataframe["SMOKE"]=encoderSMOKE.fit_transform(dataframe["SMOKE"])

encoderSCC=LabelEncoder()
dataframe["SCC"]=encoderSCC.fit_transform(dataframe["SCC"])

encoderCALC=LabelEncoder()
dataframe["CALC"]=encoderCALC.fit_transform(dataframe["CALC"])

encoderMTRANS=LabelEncoder()
dataframe["MTRANS"]=encoderMTRANS.fit_transform(dataframe["MTRANS"])

encoderNObeyesdad=LabelEncoder()
dataframe["NObeyesdad"]=encoderNObeyesdad.fit_transform(dataframe["NObeyesdad"])

dataframe.head(10)

"""**Implementación Árbol de Decisión**"""

from sklearn.metrics import accuracy_score, classification_report

y = dataframe['NObeyesdad']
X=dataframe.drop(["CAEC", "CH2O", "SCC", "FAF", "TUE", "MTRANS", "NObeyesdad"],axis=1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)
modelo = DecisionTreeClassifier(max_depth=6)
modelo.fit(X_train, y_train)

yPredict=modelo.predict(X_train)
print("Train Accuracy ",metrics.accuracy_score(y_train,yPredict))
yPredict=modelo.predict(X_test)
print("Test Accuracy ",metrics.accuracy_score(y_test,yPredict))

accuracy = accuracy_score(y_test, yPredict)
report = classification_report(y_test, yPredict)

print(f'Precisión del modelo: {accuracy}')
print('Informe de clasificación:')
print(report)

plt.rcParams['figure.figsize'] = (16, 9)
plt.style.use('ggplot')

dataframe.drop(["NObeyesdad"],axis=1).hist()
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sb
matriz=confusion_matrix(y_test,yPredict)
print(matriz)
sb.heatmap(matriz,annot=True,cmap="Blues")

from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import classification_report

precision, recall, f1, support = precision_recall_fscore_support(y_test, yPredict, average=None)
target_names = dataframe["NObeyesdad"].unique()

for i, label in enumerate(target_names):
    print(f"Métricas para {label}:")
    print(f"Precisión: {precision[i]}")
    print(f"Recuperación: {recall[i]}")
    print(f"Puntuación F1: {f1[i]}")
    print(f"Soporte: {support[i]}")

report = classification_report(y_test, yPredict, labels=target_names)
print("Informe de clasificación:")
print(report)

from sklearn.tree import DecisionTreeClassifier, export_graphviz

target_names = dataframe["NObeyesdad"].unique()
caracteristicas = X_train.columns
caracteristicas = [str(feature) for feature in caracteristicas]
target_names = [str(label) for label in target_names]
export_graphviz(modelo, out_file="arbol.dot", class_names=target_names, feature_names=caracteristicas, impurity=False, filled=True)

with open("arbol.dot") as f:
    dot_graph = f.read()
graph = graphviz.Source(dot_graph)
graph.view("arbol")

with open("arbol.dot") as f:
  dot_graph=f.read()
graphviz.Source(dot_graph)

"""**Validación cruzada**"""

from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import classification_report, accuracy_score

precision, recall, f1, support = precision_recall_fscore_support(y_test, yPredict, average='micro')
accuracy = accuracy_score(y_test, yPredict)

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)
print("Support:", support)

target_names = dataframe["NObeyesdad"].unique()
print(classification_report(y_test, yPredict, labels=target_names))